---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  cache.path = "README_cache/"
)
```


# The dvir (Disaster Victim Identification) library

We assume DNA profiles are available from victim samples (post mortem, pm data) and 
reference families (ante mortem, am, data) with missing persons (MP-s). There may be 
several samples from the same victim, potentially of low quality leading to *drop-outs*.
The problem is to identify the MP-s. Some (or all) victims may not be 
among the MP-s. Similarly, there may be MP-s not in the list of victims.
A search strategy
is implemented. All victims are initially tried, one at a time, in all MP positions.
Results are sorted according to the likelihood and assignments with a LR (compared to the null
likelihood) below a user specified limit are omitted from further search. If mutations are 
modelled all LR-s will typically be positive and the limit must be specified to a negative number
to include all possibilities in the future search. Based on this initial screening, all possible assignments
of victims are generated. Note that only a subset, possibly none, of victims may be mapped to MP-s.
The resulting list of assignments may be prohibitively large and for this reason it possible to restrict the search by
specifying that only the `nbest` assignments for each victim be considered.

## Installation

To get the latest version, install from GitHub as follows:

```{r, eval = FALSE}
 # First install devtools if needed
if(!require(devtools)) install.packages("devtools")

# Install dvir from GitHub
devtools::install_github("thoree/dvir")
```
The implementation relies heavily on 
the `ped suite` of R-libraries, in particular `forrel` and `pedmut`. These are automatically installed by the above command.

## Load libraries

We start by loading **dvir**. We also load **pedtools** for creating and plotting pedigrees.
```{r}
library(dvir)
library(pedtools)
```

## Example 1

We consider the following example

```{r}
# Attributes of a single marker
locAttr = list(name = "m", alleles = 1:3, afreq = c(1, 1, 1)/3)

# PM data (victims)
n = 7
ids.from = paste0("V", 1:n)
sex = c(rep(1, n-1), 2)
df = data.frame(famid = ids.from, id = ids.from, fid = 0, mid = 0, sex = sex,
                m = c("1/1", "2/2", "1/1", "1/1", "2/2", "2/2", "2/2"))
from = as.ped(df, locusAttributes = locAttr)

# AM data (families)
MPs = c("MP1", "MP2", "MP3")
to = nuclearPed(3, father = "R1", mother = "R2", children = MPs)
m = marker(to, "R1" = "1/1", "R2" = "1/1", name = "m")
to = setMarkers(to, m, locusAttributes = locAttr)
```


```{r ex1-ped, fig.height = 3, fig.width = 7}
# Plot both
plotPedList(list(from, to), marker = 1, 
            hatched = typedMembers, 
            col = list(red = MPs), 
            titles = c("PM data. 7 victims", "AM data. 3 MP-s"))
```

We do not consider mutations or other artefacts. We assume that copies of victim samples have been identified and merged so that without extra information like (*todo:* add age),
there are six symmetric solutions. If the ages are known, for instance 
age(V1) > age(V2) > age(V3), the solution may be unique.
Recall the convention that individuals are ordered left to right in the pedigree based on age.

### The number of assignments

The number of possible assignments is:

```{r}
ncomb(nVfemales = 1, nMPfemales = 0, nVmales = 6, nMPmales = 3)
```

The complete list of these assignments is generated as follows:

```{r} 
moves = generateMoves(from, to, MPs)
a = expand.grid.nodup(moves)
head(a)
```

### The search

The following search ranks all possible solutions by their likelihood. The ten best solutions are shown.
```{r}
res = global(from, to, MPs, moves = NULL, limit = -1, verbose = F)
res[1:10, ]
```

Next, we exemplify how to limit the search, which may be necessary in larger cases. 
First all sex-consistent marginal moves are generated. 

```{r}
moves = generateMoves(from, to, MPs)
```

Keep only the three best marginal candidates for each victim.

```{r}
moves2 = marginal(from, to,  MPs, moves, limit = -1, nkeep = 3)
res = global(from, to, MPs, moves = moves2[[1]], limit = -1, verbose = F)
head(res)
```

## Example 2

We now consider a larger dataset, loaded as follows:

```{r}
load(url("http://familias.name/BookKETP/Files/Grave.RData"))
```

The loaded dataset contains objects `from`, `to`, `ids.to` and `moves`.
```{r}
summary(from)
summary(to)
```

The family `to` has 8 missing persons, labelled MP1-MP8, and 5 genotyped family members, labelled R1-R5. The pedigree is shown below.

```{r ex2-ped}
refs = paste0("R", 1:5)
mps = paste0("MP", 1:8)
plot(to, title = "AM data", labs = c(refs, mps), hatched = c(refs, mps), 
     col = list(red = refs, blue = mps), deceased = mps)
```

The list of singletons in `from` contains female victims V1, V3, V4, V5, V6,
and male victims V2, V7, V8. The *a priori* possible number of assignments,
ignoring symmetries, is

```{r}
ncomb(nVfemales = 5, nMPfemales = 5, nVmales = 3, nMPmales = 3)
```

We restrict the number of assignments by requiring $LR > 0.99$ for *marginal* moves.
For instance, based on the below, the possibility `V1 = MP1` will be considered
since the $LR$ comparing this assignment (and no further victims identified) to the null hypothesis (no victims identified) exceeds 0.99. 

```{r}
moves = generateMoves(from, to, ids.to)
m = marginal(from, to, ids.to, limit = 0.99, moves = moves)
m$moves
```

The complete list of marginal LR values are contained in `m[[2]]`, shown below. 

```{r}
m$LR.list
```

From the above this we realise that `limit = 0` might be a better option, since it would only add `V8 = MP8` and `V2 = MP8`. However, changing to `limit = 0` would increase computation time considerably.

We perform the search using the assignments in `m$moves`:
```{r}
res1 = global(from, to, ids.to, limit = 0.99, moves = m$moves)
head(res1)
```

We check the assignment with the identification `MP8 = V8` added.

```{r}
res2 = global(from, to, ids.to, 
       moves = list(V1 = "MP1", V2 = "MP2", V3 = "MP3", V4 = "MP4",
                    V5 = "MP5", V6 = "MP6", V7 = "MP7", V8 = "MP8"))
res2
exp(res2$loglik - res1$loglik[1])
```

Finally, the code for performing an exhaustive search (i.e., `limit = 0`) is shown below. With parallelisation (activated by setting the argument `numCores` larger than 1) this computation should take around 15-20 minutes.

```{r ex2-exhaustive, cache = T, eval = T}
res3 = global(from, to, ids.to, moves = NULL, numCores = 4)
head(res3)
```



